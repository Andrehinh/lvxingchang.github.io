---
layout:     post                    # 使用的布局（不需要改）
title:      hadoop RPC机制的使用              # 标题 
subtitle:   hadoop学习笔记           
date:       2020-03-19              # 时间
author:     Lxc                      # 作者
header-img: img/post-bg-RPC.jpg    #这篇文章标题背景图片
catalog: true                       # 是否归档
tags:                               #标签
    - hadoop
    - RPC
    - Notes
---

## Hadoop-RPC底层
  RPC 是远程过程调用(Remote Procedure Call),即远程调用其他虚拟机中运行的 java object。RPC 是一种客户端/服务器模式,那么在使用时包括服务端代码和客户端代码,还有我们调用的远程过程对象。

Hadoop在实现时抛弃了JDK自带的一个RPC实现——RMI，而自己基于IPC模型实现了一个更高效的轻量级RPC。 RPC是hadoop框架运行的基础。

1. 服务端提供的对象必须是一个接口，接口extends VersioinedProtocal 。
2. 客户端对象中的方法必须位于对象的接口中。


##### **一、RPC通常采用客户端服务器模型**，其框架主要有以下几部分
- 通信模块：实现请求应该协议。主要分为同步方式和异步方式。
- stub程序：客户端和服务器均包含stub程序，可以看做代理程序。使得远程函数表现的跟本地调用一样，对用户程序完全透明。
- 调度程序：接受来自通信模块的请求消息，根据标识选择stub程序处理。并发量大一般采用线程池处理。
- 客户程序/服务过程：请求发出者和请求的处理者。

**RPC流程图**
![](https://lvxingchang.oss-cn-hangzhou.aliyuncs.com/img/20141117161630257)

-HDFS通信协议有两种，一种是Hadoop RPC接口，一种是流式接口，那么这两种接口各自有各自的分工，前者主要是负责一些连接的管理、节点的管理以及一些数据的管理，而后者主要是数据的读写传输。

不同于流式接口，Hadoop RPC接口是基于protobuf实现的，protobuf是google的一种数据格式，这里不做细究。那么Hadoop RPC的接口主要有那么几个，包括ClientProtocol，ClientDatanodeProtocol，DatanodeProtocol，InterDatanodeProtocol，NamenodeProtocol这几个，这几个接口都是节点间的主要通信接口。

##### **二、RPC接口**
- NameNode 本身就是一个 java 进程。RPC.getServer()方法的第一个参数是 this,说明 NameNode 本身就是一个位于服务端的被调用对象,即 NameNode 中的方法是可以被客户端代码调用的。根据 RPC 运行原理可知,NameNode暴露给客户端的方法位于接口中。继续查看namenode类的接口实现，可以看到 NameNode 实现了 ClientProtocal、DatanodeProtocal、NamenodeProtocal 等接口。

- hadoop 和hbase中的大部分服务都是通过hadoop.ipc.RPC这个类来实现的。hadoop.ipc.RPC 实现了一种远程过程调用的框架，应用可以直接定义过程调用的协议接口和协议的server端实现，就可以直接通过RPC框架获得RPC server和client端的接口代理。

- hadoop.ipc.RPC 的实现利用了 hadoop.ipc.Server 和 hadoop.ipc.Client这两个类， 这两个类实现了网络中非常典型的Request-Response模式服务器和客户端框架。用户可以通过定义一个协议接口并实现出Request和Response类，以及Server端的抽象处理接口(Server.call()) 就可以实现出完整的服务器程序，而客户端程序只需要在创建hadoop.ipc.Client实体时，指定协议接口和网络相关参数，然后调用 call() 就可以发送请求并获取响应。

- RPHadoop.ipc.RPC作为Hadoop的底层核心组件，在hadoop HDFS，MapReduce以及HBase中都有广泛的使用。 HDFS中NameNode，DataNode等都是通过实现对应协议的接口，然后利用hadoop.ipc.RPC获取服务器实体的。 HBase中的HBaseRPC采用的也是与hadoop.ipc.RPC类似的实现，其中的Region Server, Master Server 都是通过实现对应的协议接口直接获取服务器实体的。 hadoop.ipc将应用逻辑与网络消息的处理分离开，并且使得逻辑对象在不同的进程或组件之间有同样的语言接口，无需区分远程对象和本地对象，使得开发者可以关注于应用的处理逻辑。

##### **三、简单RPC实例**
- **新建maven project**
- **添加依赖**
maven的中心库(http://www.mvnrepository.com) 中搜索hadoop,找到Apache Hadoop Common
```VIM
<!-- http://mvnrepository.com/artifact/org.apache.hadoop/hadoop-common -->
<dependency>
    <groupId>org.apache.hadoop</groupId>
    <artifactId>hadoop-common</artifactId>
    <version>2.7.1</version>
</dependency>
```
Apache Hadoop HDFS
```java
<!-- http://mvnrepository.com/artifact/org.apache.hadoop/hadoop-hdfs -->
<dependency>
    <groupId>org.apache.hadoop</groupId>
    <artifactId>hadoop-hdfs</artifactId>
    <version>2.7.1</version>
</dependency>
````
Hadoop Mapreduce Client Core
```java
<!-- http://mvnrepository.com/artifact/org.apache.hadoop/hadoop-mapreduce-client-core -->
<dependency>
    <groupId>org.apache.hadoop</groupId>
    <artifactId>hadoop-mapreduce-client-core</artifactId>
    <version>2.7.1</version>
</dependency>
```
Hadoop Mapreduce Client Common
```java
<!-- http://mvnrepository.com/artifact/org.apache.hadoop/hadoop-mapreduce-client-common -->
<dependency>
    <groupId>org.apache.hadoop</groupId>
    <artifactId>hadoop-mapreduce-client-common</artifactId>
    <version>2.7.1</version>
</dependency>
```
一般开发mapreduce程序只需要这四个依赖,将这四个依赖复制到pom.xml中。
- **添加hadoop.version**
```java
<properties>
    <hadoop.version>2.7.1</hadoop.version>
</properties>
```
并将刚才添加的依赖的版本全都用 ${hadoop.version}来代替。

- 在src/main/java包下新建一个接口
```java
public interface IRPCInterface {
    public static final long versionID = 1;
    public String test(String s);
}
```
在hadoop1.X中，可以不指定versionID，但是如果使用hadoop2.X时必须要指定。这个ID和后面要编写的Client中的ID要保持一致。

- 新建一个server端
```java
package com.edu.hadoop;
import java.io.IOException;
import org.apache.hadoop.HadoopIllegalArgumentException;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.ipc.RPC;
import org.apache.hadoop.ipc.RPC.Server;
public class RPCServer implements IRPCInterface {
    public static void main(String[] args) throws Exception{

        Server server = new RPC.Builder(new Configuration())
        .setBindAddress("localhost")//本机地址，也可以换成IP
        .setPort(8888)
        .setInstance(new RPCServer())
        .setProtocol(IRPCInterface.class)
        .build();

        server.start();
    }

    public String test(String s) {

        System.out.println("RPCServer.test()");

        return "rpc "+s;
    }
}
```
开启服务端。
- 新建一个Client端
```java
package com.edu.hadoop;
import java.io.IOException;
import java.net.InetSocketAddress;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.ipc.RPC;
public class RPCClient {
    public static void main(String[] args) throws Exception {
        IRPCInterface proxy = RPC.getProxy(IRPCInterface.class, 1,//这里要和接口中的ID保持一直
                new InetSocketAddress("localhost", 8888), new Configuration());

        String s = proxy.test("client");

        System.out.println("client======>"+s);
    }
}
```
启动客户端，可以得到正确的从服务端修改后的字符串，服务端中也有相应的输出，测试成功。

- 两个项目之间的RPC通信
新建一个接口
```java
package com.hadoop.rpc;
public interface LoginServiceInterface {
    public static final long versionID = 1L;

    public String login(String username, String password);
}
```
一个业务方法，实现这个接口

```java
package com.hadoop.rpc;
public class LoginServiceImpl implements LoginServiceInterface {
    public String login(String username, String password) {
        // TODO Auto-generated method stub
        return username + "登陆成功！";
    }

}
```
服务端代码
```java
package com.hadoop.rpc;

import java.io.IOException;

import org.apache.hadoop.HadoopIllegalArgumentException;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.ipc.RPC;
import org.apache.hadoop.ipc.RPC.Builder;
import org.apache.hadoop.ipc.RPC.Server;

public class Starter {
    public static void main(String[] args) throws Exception {

        Builder builder = new RPC.Builder(new Configuration());

        builder.setBindAddress("localhost").setPort(10000).setProtocol(LoginServiceInterface.class).setInstance(new LoginServiceImpl());
        Server server = builder.build();

        server.start();
    }
}
```
另一个项目写客户端,将LoginServiceInterface接口也放入这个项目.
编写客户端代码

```java
package com.hadoop.rpc;

import java.io.IOException;
import java.net.InetSocketAddress;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.ipc.RPC;

public class LoginController {
    public static void main(String[] args) throws Exception {

        LoginServiceInterface proxy = (LoginServiceInterface) RPC.getProxy(
                LoginServiceInterface.class, 1L, new InetSocketAddress(
                        "localhost", 10000), new Configuration());
        String result = proxy.login("devil", "123456");
        System.out.println(result);

    }
}
```
